---
title: Integrate LM Studio with Jan
slug: /guides/integrations/lmstudio
description: Guide to integrate LM Studio with Jan
keywords:
  [
    Jan AI,
    Jan,
    ChatGPT alternative,
    local AI,
    private AI,
    conversational AI,
    no-subscription fee,
    large language model,
    LM Studio integration,
  ]
---

## Quick Introduction

With [LM Studio](https://lmstudio.ai/), you can discover, download, and run local Large Language Models (LLMs). In this guide, we will show you how to integrate and use your current models on LM Studio with Jan using 2 methods.  The first method is integrating LM Studio server with Jan UI. The second method is migrating your downloaded model from LM Studio to Jan. We will use the model [Phi 2 - GGUF](https://huggingface.co/TheBloke/phi-2-GGUF) on Hugging Face as an example.

## Steps to Integrate LM Studio server with Jan UI

### 1. Start the LM Studio server

Navigate to the `Local Inference Server` on the LM Studio application, and select the model you want to use. Then, start the server after configuring the server port and options.

![LM Studio Server](assets/05-setting-lmstudio-server.gif)

<br></br>

Modify the `openai.json` file in the `~/jan/engines` folder to include the full URL of the LM Studio server.

```json title="~/jan/engines/openai.json"
{
  "full_url": "http://localhost:<port>/v1/chat/completions"
}
```

:::tip

- Replace `<port>` with the port number you set in the LM Studio server. The default port is `1234`.

:::

### 2. Modify a Model JSON

Navigate to the `~/jan/models` folder. Create a folder named `<lmstudio-modelname>`, for example, `lmstudio-phi-2` and create a `model.json` file inside the folder including the following configurations:

- Ensure the filename must be `model.json`.
- Ensure the `format` property is set to `api`.
- Ensure the `engine` property is set to `openai`.
- Ensure the `state` property is set to `ready`.

```json title="~/jan/models/lmstudio-phi-2/model.json"
{
  "sources": [
    {
      "filename": "phi-2-GGUF",
      "url": "https://huggingface.co/TheBloke/phi-2-GGUF"
    }
  ],
  "id": "lmstudio-phi-2",
  "object": "model",
  "name": "LM Studio - Phi 2 - GGUF",
  "version": "1.0",
  "description": "TheBloke/phi-2-GGUF",
  // highlight-next-line
  "format": "api",
  "settings": {},
  "parameters": {},
  "metadata": {
    "author": "Microsoft",
    "tags": ["General", "Big Context Length"]
  },
  // highlight-start
  "engine": "openai"
  // highlight-end
}
```

### 3. Start the Model

Restart Jan and navigate to the Hub. Locate your model and click the Use button.

![LM Studio Model](assets/05-lmstudio-run.png)

### 4. Try Out the Integration of Jan and LM Studio

![LM Studio Integration Demo](assets/05-lmstudio-integration-demo.gif)

## Steps to Migrate Your Downloaded Model from LM Studio to Jan

### 1. Migrate Your Downloaded Model

Navigate to `My Models` in the LM Studio application and reveal the model folder.

![Reveal-model-folder-lmstudio](assets/05-reveal-model-folder-lmstudio.gif)

Copy the model folder that you want to migrate to `~/jan/models` folder.

Ensure the folder name property is the same as the model name of `.gguf` filename by changing the folder name if necessary. For example, in this case, we changed foldername from `TheBloke` to `phi-2.Q4_K_S`.

### 2. Start the Model

Restart Jan and navigate to the Hub. Jan will automatically detect the model and display it in the Hub. Locate your model and click the Use button for trying out the migrating model.

![Demo](assets/05-demo-migrating-model.gif)